library(jsonlite)
library(tidyverse)
library(tidytext)
speeches <- fromJSON("speeches.json")
speeches
View(speeches)
speeches[0]
speeches[1]
s <- speeches[1]
View(s)
s <- speeches[1, 1]
s <- speeches[1][1]
speeches <- fromJSON("speeches.json")
View(speeches)
speeches <- fromJSON("speeches.json")
speeches %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigrams <- speeches %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
View(bigrams)
bigrams %>%
count(bigram, sort = TRUE)
bigrams <- speeches %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stopwords$word) %>%
filter(!word2 %in% stopwords$word)
bigrams <- speeches %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
bigrams %>%
count(bigram, sort = TRUE)
bigrams %>%
count(word1, word2, sort = TRUE)
bigrams <- speeches %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
bigrams
bigrams %>%
count(speaker, word1, word2, sort = TRUE)
words <- speeches %>%
unnest_tokens(word, text) %>%
filter(!word %in% stop_words$word)
words
lilbrary(widyr)
library(widyr)
install.packages("widyr")
library(widyr)
words %>%
pairwise_count(word, speaker, sort = TRUE)
bigrams %>%
count(speaker, word1, word2, sort = TRUE)
bigrams %>%
count(word1, word2, sort = TRUE)
bigrams %>%
group_by(speaker) %>%
count(word1, word2, sort = TRUE)
bigrams %>%
count(word1, word2, sort = TRUE)
bigrams %>%
group_by(speaker) %>%
count(word1, word2, sort = TRUE)
bigrams %>%
count(speaker, word1, word2, sort = TRUE)
bigrams %>%
group_by(speaker) %>%
count(word1, word2, sort = TRUE)
bigrams %>%
# group_by(speaker) %>%
count(word1, word2, sort = TRUE)
